{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d769b8a",
   "metadata": {},
   "source": [
    "# Using a custom text classifier\n",
    "\n",
    "Now that we've built a custom text classifier, let's try to use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q transformers sentencepiece huggingface_hub sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c48402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import huggingface_hub\n",
    "import requests\n",
    "import os.path\n",
    "\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e7214",
   "metadata": {},
   "source": [
    "## Load in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"wapo-app-reviews-huggingface-full.csv\"):\n",
    "    print(\"Downloading dataset\")\n",
    "    response = requests.get(\"https://raw.githubusercontent.com/jsoma/nicar23-huggingface/main/data/wapo-app-reviews-huggingface-full.csv\")\n",
    "    with open('wapo-app-reviews-huggingface-full.csv', 'w') as f:\n",
    "        f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wapo-app-reviews-huggingface-full.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32b999",
   "metadata": {},
   "source": [
    "## Use our model\n",
    "\n",
    "We've set our model to private, so we'll need to log in to Hugging Face to be able to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2243ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe37f92",
   "metadata": {},
   "source": [
    "But once we do that, we can use the model just like we used for the sentiment analysis notebook!\n",
    "\n",
    "**You'll need to change the `model=\"XXXXXX\"` line to match your model's name.** Mine was something like `wendys-llc/autotrain-wapo-v3-38832102021` (I recommend using the copy button at the top of your model's web page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39d47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    # tokenizer=\"wendys-llc/autotrain-wapo-v3-38832102021\",\n",
    "    model=\"wendys-llc/autotrain-wapo-v3-38832102021\",\n",
    "    use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d13597",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sentiment_pipeline(df.Review.tolist())\n",
    "results = pd.DataFrame(results).add_prefix('prediction_')\n",
    "scored = df.join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a09180",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored.sort_values(by=['prediction_label', 'prediction_score'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored.prediction_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1780e6",
   "metadata": {},
   "source": [
    "## But how did it really do?\n",
    "\n",
    "While we have measurements like \"precision\" and \"accuracy\" and \"recall,\" looking at the actual results in tiny boxes is far more useful than those abstract numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# The predictions are string 0 and 1, so we\n",
    "# need to convert the 'sexual' column\n",
    "y_true = scored.sexual.replace({0: '0', 1: '1'})\n",
    "y_pred = scored.prediction_label\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['not creepy', 'creepy'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
